{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_7_2_KalmanFilter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glA3NV9MRl63",
        "colab_type": "text"
      },
      "source": [
        "# Kalman Filter - Lab 7.2\n",
        "\n",
        "## Recap\n",
        "This is the Lab on using a Kalman Filter in CE6003's Object Tracking. You should complete the tasks in this lab as part of the Kalman Filter section of the lesson.\n",
        "\n",
        "Please remember this lab must be completed before taking the quiz at the end of this lesson.\n",
        "\n",
        "First, if we haven't already done so, we need to clone the various images and resources needed to run these labs into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1qGUkYR6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/mcnamarad1971/CE6003.git\n",
        "!git clone https://github.com/EmdaloTechnologies/CE6003.git\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvp_ecbWSB6V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Program Description**\n",
        "\n",
        "This program demonstrates a very simple 'tracking' mechanism - derived from a Kalman filter. We're going to use our Kalman filter to track a single object, namely a person.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWvUXFH1iaoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import clear_output, Image, display\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GSU76keSNr7",
        "colab_type": "text"
      },
      "source": [
        "#The Story So Far\n",
        "\n",
        "To illustrate how to track something in a video stream, we have used the following technique to generate a set of images for you to work on.\n",
        "\n",
        "What we did was we generated a short video - just recording one person walking around, on an iPhone.\n",
        "\n",
        "Then we used ```ffmpeg``` to decompose about 7 seconds of that video down into still images.\n",
        "\n",
        "```ffmpeg -i $vid_in -vf fps=30 imgs/daire%03d.png```\n",
        "\n",
        "We saved those frames as ```imgs/daire%03d.png``` in the git repository in the single-detections directory\n",
        "\n",
        "We've run yolo3 over those frames to generate bounding boxes and saved those bounding boxes into the same directory.\n",
        "\n",
        "The file format is comma-separated values and the values are as shown here:\n",
        "\n",
        " frame index | object-type | centre-x | centre-y | width | height | confidence\n",
        " --- | --- | --- | --- | --- | --- | ---\n",
        " int | -1 | float | float | float | float | float\n",
        "\n",
        "* The object type is always a person - that's all we inferred for.\n",
        "* The centre-x and width are fractions of the image's width\n",
        "* The centre-y and height are fractions of the image's height\n",
        "* The confidence is supplied by Yolo3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWphuuLX6hr",
        "colab_type": "text"
      },
      "source": [
        "*What Happens Now*\n",
        "\n",
        "For each image in the directory, in order,\n",
        "* we'll find the centre of the detection in that image (if any)\n",
        "* we'll build a bounding box for the detection in that image\n",
        "* we'' derive a variance term (crudely) from the Yolo confidence for that image\n",
        "* and we'll supply the centre of that bounding box along with the variance term to a Kalman Filter implementation\n",
        "\n",
        "Then, we'll explore how a Kalman filter tracks the object in the image stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsQyMnFpZBUP",
        "colab_type": "text"
      },
      "source": [
        "**Get File Handles**\n",
        "\n",
        "This function gets the filenames of all the files in the directory, in a reproducible order, and loads in the bounding boxes from file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lGqvyGZBjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pngs_and_boxes():\n",
        "    pngdir = \"/content/CE6003/images/lab7/single-objects/\"\n",
        "    bbdir = \"/content/CE6003/images/lab7/single-objects/\"\n",
        "\n",
        "    pngfolder = os.fsencode(pngdir)\n",
        "    bbfolder = os.fsencode(bbdir)\n",
        "\n",
        "    pngfiles = []\n",
        "    for filename in os.listdir(pngfolder):\n",
        "        if filename.decode().endswith(\".png\"):\n",
        "            pngfiles.append(pngdir + filename.decode())\n",
        "    pngfiles.sort()\n",
        "\n",
        "    for filename in os.listdir(bbfolder):\n",
        "        if filename.decode().endswith(\".boxes\"):\n",
        "            bbfilename = bbdir + filename.decode()\n",
        "\n",
        "    bb = open(bbfilename, \"r\")\n",
        "    bb_lines = bb.readlines()\n",
        "    bb.close()\n",
        "\n",
        "    return bb_lines, pngfiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDJASmq8ZrwJ",
        "colab_type": "text"
      },
      "source": [
        "**Parse Detections**\n",
        "\n",
        "We'll use this function in the main loop to wrangle the detections into the format we want to supply to our Kalman Filter.\n",
        "\n",
        "Essentially it takes the name of png file, an img object and the list of bounding boxes as inputs.\n",
        "\n",
        "It then finds the correct record (if any) for that image in the bounding boxes list and converts the bounding box parameters into a format which we'll use for the rest of the program (it converts back to absolute pixel values).\n",
        "\n",
        "It returns a centre and a confidence value for the image supplied to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQw8QFkqZxMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_detections(bboxes, pngfile, img):\n",
        "    # Sample Line: 400,-1,0.285417,0.241667,0.094792,0.483333,0.999797,-1,-1,-1\n",
        "    # Index, object type,\n",
        "    # x    - centre of bounding box (as fraction of image width\n",
        "    # y    - centre of bounding box (as fraction of image height\n",
        "    # w    - width of bounding box (as fraction of image width)\n",
        "    # h    - height of bounding box (as fraction of image height\n",
        "    # prob, _,_,_\n",
        "\n",
        "    # extract the frame index of the png file - \n",
        "    # use it to find the detections for that frame\n",
        "    index = int(re.findall(r'\\d+', pngfile)[-1])\n",
        "    imgh, imgw = img.shape[:2]\n",
        "\n",
        "    centre = np.zeros(shape=(2, 1))\n",
        "    P = 0.000001 # hack to avoid div by zero\n",
        "    for line in bboxes:\n",
        "        np_array = np.genfromtxt(io.StringIO(line), delimiter=\",\")\n",
        "        lineindex = int(np_array[0])\n",
        "\n",
        "        if lineindex == index:\n",
        "            centre = np_array[2:4]\n",
        "            P += np_array[6]\n",
        "            centre[0] *= imgw\n",
        "            centre[1] *= imgh\n",
        "\n",
        "            return centre, P\n",
        "\n",
        "    return centre, P\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuM6UO7Jan5V",
        "colab_type": "text"
      },
      "source": [
        "**Kalman 2D**\n",
        "\n",
        "This function specialises the kalman() routine below for a particular model.\n",
        "\n",
        "In this example, we are going to create a 2D Kalman - so a term for x (pos,vel). and a term for y (pos,vel), with constant velocity.  We'll set up for a constant velocity model.\n",
        "\n",
        "\n",
        "### State Terms\n",
        "Therefore our state will be represented by 4 terms\n",
        "\n",
        "$xstate = \\begin{bmatrix}\n",
        "    x_{pos} \\\\\n",
        "    y_{pos} \\\\\n",
        "    \\dot{x} \\\\\n",
        "    \\dot{y} \n",
        "  \\end{bmatrix}$\n",
        "\n",
        "Note: the x in x_state is separate from $x_{pos}.\n",
        "\n",
        "### State Covariance\n",
        "Our state uncertainty covariance matrix will have a $4 \\times 4$ shape.\n",
        "We'll supply something like\n",
        "\n",
        "$P = \\begin{bmatrix}\n",
        "  400 && 0 && 0 && 0 \\\\\n",
        "  0 && 400 && 0 && 0 \\\\\n",
        "  0 && 0 && 400 && 0 \\\\\n",
        "  0 && 0 && 0 && 400 \\\\\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "to this matrix later on, indicating a high initial degree of uncertainty around all of our state parameters.\n",
        "\n",
        "### Motion Terms\n",
        "**Removal of Motion Term**\n",
        "\n",
        "In this example, we're not going to have a motion term, so we'll set motion up as empty.\n",
        "\n",
        "$motion = \\begin{bmatrix}\n",
        "  0 &&\n",
        "  0 &&\n",
        "  0 &&\n",
        "  0\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "and we'll set up the motion noise as an Identity matrix to multiplication through this matrix will be result in the same term coming back out as went in.\n",
        "\n",
        "$Q = \\begin{bmatrix}\n",
        " 1 && 0 && 0 && 0 \\\\\n",
        " 0 && 1 && 0 && 0 \\\\\n",
        " 0 && 0 && 1 && 0 \\\\\n",
        " 0 && 0 && 0 && 1\n",
        " \\end{bmatrix}$\n",
        "\n",
        "### Measurement Terms\n",
        "We'll supply a measurement term later on. In terms of shape its going to represent what we can measure - i.e. $x_{pos}$ and $y_{pos}$\n",
        "So, \n",
        "\n",
        "$measurement = \\begin{bmatrix}\n",
        " x_{pos} \\\\\n",
        " y_{pos} \\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        "### Measurement uncertainty covariance\n",
        "Again, we'll supply our measurement co-variance values later on, but, in terms of shape it will look something like this.\n",
        "\n",
        "$R = \\begin{bmatrix}\n",
        "  x_{noise} && 0 \\\\\n",
        "  0 && y_{noise}\n",
        " \\end{bmatrix}$\n",
        "\n",
        " And we'll derive $x_{noise}$ and $y_{noise}$ from yolo later on.\n",
        "\n",
        "Finally, we'll use two shape terms to tell a generic Kalman Filter algorithm what terms to multiply at each stage.\n",
        "\n",
        "$F$ will enforce the constant velocity model on the process.\n",
        "\n",
        "$F =\\begin{bmatrix}\n",
        "  1 && 0 && 1 && 0 \\\\\n",
        "  0 && 1 && 0 && 1 \\\\\n",
        "  0 && 0 && 1 && 0 \\\\\n",
        "  0 && 0 && 0 && 1\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "$H$ effectively informs the other matrices in ```kalman()``` below that we are only measuring $x_{pos}$ and $y_{pos}$\n",
        "\n",
        "$H=\\begin{bmatrix}\n",
        "            1 && 0 && 0 && 0 \\\\\n",
        "            0 && 1 && 0 && 0\n",
        " \\end{bmatrix}$\n",
        "\n",
        "Finally, we initialise everything using floats, to get a self-consistent set of data types - everything is floating point,\n",
        "\n",
        "With that done, we have specialised the ```kalman()``` routine to perform Kalman Filtering in both x and v, using a constant velocity model, with no motion term.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZAHf_dQau78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kalman_2d(x, P, measurement, R, motion=np.matrix('0. 0. 0. 0.').T, Q=np.matrix(np.eye(4))):\n",
        "\n",
        "    return kalman(x, P, measurement, R, motion, Q,\n",
        "        # Process matrix, assuming constant velocity model (x, y, x_dot, y_dot)\n",
        "        F=np.matrix('''\n",
        "            1. 0. 1. 0.;\n",
        "            0. 1. 0. 1.;\n",
        "            0. 0. 1. 0.;\n",
        "            0. 0. 0. 1.\n",
        "            '''),\n",
        "        # Measurement matrix, assuming we can only measure \n",
        "        # the co-ordinates x, y\n",
        "        H=np.matrix('''\n",
        "            1. 0. 0. 0.;\n",
        "            0. 1. 0. 0.\n",
        "            '''))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4RRg22Hitb5",
        "colab_type": "text"
      },
      "source": [
        "#Kalman Filter\n",
        "\n",
        "Derived from Wikipedia\n",
        "\n",
        "    See http://en.wikipedia.org/wiki/Kalman_filter\n",
        "\n",
        "Look back over Kalman Introduction and Kalman Maths for an insight into how Kalman is operating.\n",
        "\n",
        "The concept is:\n",
        "* For a low computational cost\n",
        "* Generate a state update/prediction\n",
        "* Generate a measurement prediction from that state\n",
        "* Calculate the difference between the predicted measurement and the actual measurement\n",
        "* Adjust the state update/prediction, and repeat....\n",
        "\n",
        "All done on normal probabilities - i.e. means and co-variances.  Effectively each key term is held as two parameters - a mean term and a covariance term for that mean.\n",
        "\n",
        "To this filter, we supply the old state / variance and the new measurement value / variance and we take away a new state / variance.\n",
        "\n",
        "Two key terms to watch are the state covariance term and the measurement variance term as their interaction influences the filter responsiveness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn7nKwdli4e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kalman(x, P, measurement, R, motion, Q, F, H):\n",
        "    '''\n",
        "    Dynamic Parameters\n",
        "    x: state\n",
        "    P: state uncertainty covariance\n",
        "    measurement: measurement\n",
        "    R: measurement noise\n",
        "\n",
        "    return:\n",
        "        updated and predicted new values for (x, P)\n",
        "    '''\n",
        "\n",
        "    # Update Step\n",
        "    # Update x and P based on measurement m\n",
        "    # distance between measured and current position-belief\n",
        "    y = np.matrix(measurement).T - H * x\n",
        "\n",
        "    S = H * P * H.T + R\n",
        "    K = P * H.T * S.I\n",
        "    x = x + K * y\n",
        "    I = np.matrix(np.eye(F.shape[0]))\n",
        "    P = (I - K*H)*P\n",
        "\n",
        "    # Predict Step\n",
        "    # Predict x and P based on motion\n",
        "    x = F*x + motion\n",
        "    P = F*P*F.T + Q\n",
        "\n",
        "    return x, P\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dlyv0Nk7EU",
        "colab_type": "text"
      },
      "source": [
        "##Demo\n",
        "\n",
        "### Program Execution\n",
        "For each file:\n",
        "* get centre of detection (if any) and confidence from Yolo\n",
        "* feed Kalman with these values\n",
        "* Extract $x_{pos}$ and $y_{pos}$ from Kalman state term.\n",
        "* Print original centre of detection\n",
        "* Print filtered centre of detection\n",
        "\n",
        "### Initialisation\n",
        "We need to initialize the state vector.  We'll initialise it to all zeros.\n",
        "\n",
        "\n",
        "$x = \\begin{bmatrix}\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "\n",
        "and we need to initialize the state covariance matrix.  We'll initialise it to all highly uncertain.\n",
        "\n",
        "$P = \\begin{bmatrix}\n",
        " 100 && 0 && 0 && 0 \\\\\n",
        " 0 && 100 && 0 && 0 \\\\\n",
        " 0 && 0 && 100 && 0 \\\\\n",
        " 0 && 0 && 0 && 100\n",
        " \\end{bmatrix}$\n",
        "\n",
        " And we'll set up a matrix to hold R, the measurement uncertainty.\n",
        "\n",
        " $R = \\begin{bmatrix}\n",
        "  0 && 0 \\\\\n",
        "  0 && 0 \n",
        "  \\end{bmatrix}$\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tX2yoKlFiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = None\n",
        "\n",
        "def demo_kalman_2d():\n",
        "    global writer\n",
        "    # Initialise state (x, y, x_dot, y_dot) to no position\n",
        "    x = np.matrix('0. 0. 0. 0.').T\n",
        "    # Initialise uncertainty to all highly uncertain\n",
        "    P = np.matrix(np.eye(4))*100\n",
        "\n",
        "    raw_centres = []        # a list of unfiltered centres\n",
        "    filtered_centres = []   # a list of filtered centres\n",
        "\n",
        "    R = np.zeros(shape=(2, 2))  # a shape to hold measurement uncertainty\n",
        "\n",
        "    bb_lines, pngfiles = get_pngs_and_boxes()\n",
        "\n",
        "    for pngfile in pngfiles:\n",
        "        #print(\"handling ..\" + os.path.basename(pngfile))\n",
        "        img = cv2.imread(pngfile)\n",
        "\n",
        "        # Derive R from yolo confidence level in detection\n",
        "        raw_centre, conf = parse_detections(bb_lines, pngfile, img)\n",
        "\n",
        "        # Crudely derive R.  If yolo is confident we want a small\n",
        "        # uncertainty. If yolo isn't confident, translate to\n",
        "        # a large uncertainty.\n",
        "        R *= 1/conf\n",
        "\n",
        "        # Keep track of unfiltered bounding box centres - these will be\n",
        "        # the basis of our Kalman\n",
        "        raw_centres.append(raw_centre.astype(int))\n",
        "\n",
        "        # reshape for Kalman - it expects\n",
        "        # [x]\n",
        "        # [y]\n",
        "        # not [x,y]\n",
        "        observed = raw_centre.reshape(1, 2)\n",
        "\n",
        "        # Update the Kalman\n",
        "        x, P = kalman_2d(x, P, observed, R)\n",
        "\n",
        "        # just track x and y values from Kalman state\n",
        "        # (we just want to visualise positions)\n",
        "        filtered_centre = x[:2]\n",
        "\n",
        "        # Keep track of filtered x & y values\n",
        "        filtered_centres.append(filtered_centre)\n",
        "\n",
        "        # Pretty print a track of original centres\n",
        "        # and filtered centres\n",
        "        for i in range(1, len(raw_centres)):\n",
        "            # print unfiltered\n",
        "            cv2.line(img, tuple(raw_centres[i-1]), \n",
        "                     tuple(raw_centres[i]), (0, 255, 0), 20)\n",
        "\n",
        "            # print filtered\n",
        "            cv2.line(img, tuple(filtered_centres[i-1]), \n",
        "                     tuple(filtered_centres[i]), (255, 0, 0), 20)\n",
        "\n",
        "        # Resize and show the image\n",
        "        img2 = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
        "\n",
        "        # Build a frame of our output video\n",
        "        if writer is None:\n",
        "            # Initialize our video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'VP80')\n",
        "            writer = cv2.VideoWriter('video.webm', fourcc, 30, (img2.shape[1], img2.shape[0]), True)\n",
        "\n",
        "        # Write the output frame to disk\n",
        "        writer.write(img2)\n",
        "\n",
        "    # Release the file pointers\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "demo_kalman_2d()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fZJvZXeY15y",
        "colab_type": "text"
      },
      "source": [
        "**Video**\n",
        "\n",
        "Thia code plays the video we just made.\n",
        "\n",
        "The Kalman Filtered track plays in green, the unfilterered track plays in blue.\n",
        "\n",
        "As you can see, the Kalman Filtering has a role to play in predicting a reasonable guess for where the object might be while it is off-camera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxvG8It3RlWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set this to 1 if video display\n",
        "# is not working - works with chrome and firefox, not with safari\n",
        "videoBodge = 0\n",
        "\n",
        "def arrayShow (imageArray):\n",
        "    ret, png = cv2.imencode('.png', imageArray)\n",
        "    encoded = base64.b64encode(png)\n",
        "    return Image(data=encoded.decode('ascii'))\n",
        "\n",
        "if(videoBodge == 0):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "    webm = open('video.webm','rb').read()\n",
        "    data_url = \"data:video/webm;base64,\" + b64encode(webm).decode()\n",
        "else:\n",
        "    video = cv2.VideoCapture(\"video.webm\")\n",
        "    while(video.isOpened()):\n",
        "        clear_output(wait=True)\n",
        "        ret, frame = video.read()\n",
        "        if(ret == False):\n",
        "          break\n",
        "        lines, columns, _ =  frame.shape\n",
        "        img = arrayShow(frame)\n",
        "        display(img)\n",
        "        time.sleep(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DewKk12799jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Video\n",
        "HTML(\"\"\"\n",
        "<video width=200 controls>\n",
        "      <source src=\"%s\" type=\"video/webm\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4IGJkZlO_u",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "## Exercises\n",
        "**Exercise 1**\n",
        "Simulate occluding the object being detected - for example, only supply every second measurement update to the Kalman algorithm and observe the Kalman predictions.\n",
        "\n",
        "**Exercise 2**\n",
        "Again, similarly to the Bayes lab, vary the state covariance and the measurement covariance relative to each other and observe how that affects the Kalman Filter's predictions.\n",
        "\n",
        "**Advanced Exercise**\n",
        "Think about how you might extend the model to account for acceleration in x and y.\n",
        "\n",
        "## Takeaways\n",
        "1. You've seen a Kalman Filter used for single object tracking\n",
        "2. You've seen that a Kalman Filter can help deal with occlusions - i.e. in this example the object being tracked disappeared for a few frames and the Kalman continued to predict motion for it based on its model.\n",
        "3. You've seen that a typical approach to writing a Kalman is to develop the core algorithm independent of the number of terms in the state variable and to specialise it for a particular model.\n",
        "\n",
        "## Next Steps\n",
        "1. We'll see the Kalman's strengths lie with predictable behaviour (typically referred to as a linear model) and we'll look at a derivitive technique (the Particle Filter) that attempts to improve the Kalman in the presence of less predictable behaviour (aka a non-linear model)."
      ]
    }
  ]
}