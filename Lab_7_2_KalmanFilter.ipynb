{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab_7_2_KalmanFilter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glA3NV9MRl63",
        "colab_type": "text"
      },
      "source": [
        "# Kalman Filter - Lab 7.2\n",
        "\n",
        "## Recap\n",
        "This is the Lab on using a Kalman Filter in CE6003's Object Tracking. You should complete the tasks in this lab as part of the Kalman Filter section of the lesson.\n",
        "\n",
        "Please remember this lab must be completed before taking the quiz at the end of this lesson.\n",
        "\n",
        "First, if we haven't already done so, we need to clone the various images and resources needed to run these labs into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1qGUkYR6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/EmdaloTechnologies/CE6003.git\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvp_ecbWSB6V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Program Description**\n",
        "\n",
        "This program demonstrates a very simple 'tracking' mechanism - derived from a Kalman filter. We're going to use our Kalman filter to track a single object, namely a person.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWvUXFH1iaoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import clear_output, Image, display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GSU76keSNr7",
        "colab_type": "text"
      },
      "source": [
        "#The Story So Far\n",
        "\n",
        "To illustrate how to track something in a video stream, we have used the following technique to generate a set of images for you to work on.\n",
        "\n",
        "What we did was we generated a short video - just recording one person walking around, on an iPhone.\n",
        "\n",
        "Then we used ```ffmpeg``` to decompose about 7 seconds of that video down into still images.\n",
        "\n",
        "```ffmpeg -i $vid_in -vf fps=30 imgs/daire%03d.png```\n",
        "\n",
        "We saved those frames as ```imgs/daire%03d.png``` in the git repository in the single-detections directory\n",
        "\n",
        "We've run yolo3 over those frames to generate bounding boxes and saved those bounding boxes into the same directory.\n",
        "\n",
        "The file format is comma-separated values and the values are as shown here:\n",
        "\n",
        " frame index | object-type | centre-x | centre-y | width | height | confidence\n",
        " --- | --- | --- | --- | --- | --- | ---\n",
        " int | -1 | float | float | float | float | float\n",
        "\n",
        "* The object type is always a person - that's all we inferred for.\n",
        "* The centre-x and width are fractions of the image's width\n",
        "* The centre-y and height are fractions of the image's height\n",
        "* The confidence is supplied by Yolo3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWphuuLX6hr",
        "colab_type": "text"
      },
      "source": [
        "*What Happens Now*\n",
        "\n",
        "For each image in the directory, in order,\n",
        "* we'll find the centre of the detection in that image (if any)\n",
        "* we'll build a bounding box for the detection in that image\n",
        "* we'' derive a variance term (crudely) from the Yolo confidence for that image\n",
        "* and we'll supply the centre of that bounding box along with the variance term to a Kalman Filter implementation\n",
        "\n",
        "Then, we'll explore how a Kalman filter tracks the object in the image stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsQyMnFpZBUP",
        "colab_type": "text"
      },
      "source": [
        "**Get File Handles**\n",
        "\n",
        "This function gets the filenames of all the files in the directory, in a reproducible order, and loads in the bounding boxes from file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lGqvyGZBjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pngs_and_boxes():\n",
        "    pngdir = \"/content/CE6003/images/lab7/single-objects/\"\n",
        "    bbdir = \"/content/CE6003/images/lab7/single-objects/\"\n",
        "\n",
        "    pngfolder = os.fsencode(pngdir)\n",
        "    bbfolder = os.fsencode(bbdir)\n",
        "\n",
        "    pngfiles = []\n",
        "    for filename in os.listdir(pngfolder):\n",
        "        if filename.decode().endswith(\".png\"):\n",
        "            pngfiles.append(pngdir + filename.decode())\n",
        "    pngfiles.sort()\n",
        "\n",
        "    for filename in os.listdir(bbfolder):\n",
        "        if filename.decode().endswith(\".boxes\"):\n",
        "            bbfilename = bbdir + filename.decode()\n",
        "\n",
        "    bb = open(bbfilename, \"r\")\n",
        "    bb_lines = bb.readlines()\n",
        "    bb.close()\n",
        "\n",
        "    return bb_lines, pngfiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDJASmq8ZrwJ",
        "colab_type": "text"
      },
      "source": [
        "**Parse Detections**\n",
        "\n",
        "We'll use this function in the main loop to wrangle the detections into the format we want to supply to our Kalman Filter.\n",
        "\n",
        "Essentially it takes the name of png file, an img object and the list of bounding boxes as inputs.\n",
        "\n",
        "It then finds the correct record (if any) for that image in the bounding boxes list and converts the bounding box parameters into a format which we'll use for the rest of the program (it converts back to absolute pixel values).\n",
        "\n",
        "It returns a centre and a confidence value for the image supplied to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQw8QFkqZxMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_detections(bboxes, pngfile, img):\n",
        "    # Sample Line: 400,-1,0.285417,0.241667,0.094792,0.483333,0.999797,-1,-1,-1\n",
        "    # Index, object type,\n",
        "    # x    - centre of bounding box (as fraction of image width\n",
        "    # y    - centre of bounding box (as fraction of image height\n",
        "    # w    - width of bounding box (as fraction of image width)\n",
        "    # h    - height of bounding box (as fraction of image height\n",
        "    # prob, _,_,_\n",
        "\n",
        "    # extract the frame index of the png file - \n",
        "    # use it to find the detections for that frame\n",
        "    index = int(re.findall(r'\\d+', pngfile)[-1])\n",
        "    imgh, imgw = img.shape[:2]\n",
        "\n",
        "    centre = np.zeros(shape=(2, 1))\n",
        "    P = 0.000001 # hack to avoid div by zero\n",
        "    for line in bboxes:\n",
        "        np_array = np.genfromtxt(io.StringIO(line), delimiter=\",\")\n",
        "        lineindex = int(np_array[0])\n",
        "\n",
        "        if lineindex == index:\n",
        "            centre = np_array[2:4]\n",
        "            P += np_array[6]\n",
        "            centre[0] *= imgw\n",
        "            centre[1] *= imgh\n",
        "\n",
        "            return centre, P\n",
        "\n",
        "    return centre, P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuM6UO7Jan5V",
        "colab_type": "text"
      },
      "source": [
        "**Kalman 2D**\n",
        "\n",
        "This function specialises the kalman() routine below for a particular model.\n",
        "\n",
        "In this example, we are going to create a 2D Kalman, and we'll use a constant velocity model - so we'll use a term for x (expressed as position and velocity) and a term for y (also expressed as position and velocity).\n",
        "\n",
        "### State Estimate Term\n",
        "Therefore our state estimate will be represented by 4 state terms\n",
        "\n",
        "$x_{state} = \\begin{bmatrix}\n",
        "    x_{pos} \\\\\n",
        "    y_{pos} \\\\\n",
        "    \\dot{x} \\\\\n",
        "    \\dot{y} \n",
        "  \\end{bmatrix}$\n",
        "\n",
        "Note: the $x$ in $x_{state}$ is separate from $x_{pos}$.\n",
        "\n",
        "\n",
        "### State Estimate Error Covariance\n",
        "Our state estimate error covariance matrix will have a $4 \\times 4$ shape.\n",
        "We'll supply something like:\n",
        "\n",
        "$P_{0} = \\begin{bmatrix}\n",
        "  100 &&   0 &&   0 &&   0 \\\\\n",
        "  0   && 100 &&   0 &&   0 \\\\\n",
        "  0   &&   0 && 100 &&   0 \\\\\n",
        "  0   &&   0 &&   0 && 100 \\\\\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "to this matrix later on to initialize our state estimate error covariance, indicating a high initial degree of uncertainty around each of our state parameters and indicating an initial belief that the uncertainty in each state term is not linked to the uncertainty in the other state terms.\n",
        "\n",
        "This is a measure of the initialial estimated accuracy of the state estimate $x_{state}$ above.\n",
        "\n",
        "Its typical to initialize $P$ by setting the diagonal elements to the uncertainty in your initial values of the state and normally to quite a large value. \n",
        "\n",
        "The measurements will normally bring the state estimate error covariances down when running the filter and in almost all cases, the off diagonal elements will become non-zero as the filter works.\n",
        "\n",
        "For the case of the simple 2 state position-velocity filter, the off diagonal matrix elements make sure that if you do have a velocity measurement, that the position is also corrected. So, the state estimate error covariance matrix 'learns' how variance in one state term affects the variance in the other state terms.\n",
        "\n",
        "### Process Noise Covariance\n",
        "\n",
        "We'll initialise the process noise covariance as an Identity matrix as shown here.  We're setting it up along the diagonal because this is a reasonable way to set up when we have no good information about the process.  You can better model this term (particularly for more advanced filters) but for our purposes it leads to satisfactory tracking.  Essentially we are saying that we believe each state term is effectively independent of each other state term.  It turns out that even in cases where this is patently not true, it leads to reasonable behaviour and obviates the need to a detailed process model - which suits our purposes in this demonstration.\n",
        "\n",
        "$Q_{0} = \\begin{bmatrix}\n",
        " 1 && 0 && 0 && 0 \\\\\n",
        " 0 && 1 && 0 && 0 \\\\\n",
        " 0 && 0 && 1 && 0 \\\\\n",
        " 0 && 0 && 0 && 1\n",
        " \\end{bmatrix}$\n",
        "\n",
        "\n",
        "### Measurement Terms\n",
        "\n",
        "We'll supply a measurement term (aka an observation term) later on dynamically to the filter for each frame we process. In terms of the shape of the measurement term its going to represent what we can measure - i.e. $x_{pos}$ and $y_{pos}$. So, our measurement term will be of this form:\n",
        "\n",
        "$measurement = \\begin{bmatrix}\n",
        " x_{pos} \\\\\n",
        " y_{pos} \\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        "### Measurement uncertainty covariance\n",
        "Again, we'll supply our measurement noise co-variance values (aka our observation nose covariance) later on dynamically, but, in terms of shape it will look like this.  We're assuming empirically a certain measurement noise in the two terms we're measuring $x_{pos}$ and $y_{pos}$.\n",
        "\n",
        "$R = \\begin{bmatrix}\n",
        "  x_{noise} && 0 \\\\\n",
        "  0 && y_{noise}\n",
        " \\end{bmatrix}$\n",
        "\n",
        "We'll derive empirically $x_{noise}$ and $y_{noise}$ from yolo later for each frame we process.\n",
        "\n",
        "### State-Transition Model and Observation Model\n",
        "Finally, we'll use two shape terms to tell a generic Kalman Filter algorithm what terms to multiply at each stage.\n",
        "\n",
        "$F$, the state transition model, will effectively enforce the constant velocity model on the process.\n",
        "\n",
        "$F =\\begin{bmatrix}\n",
        "  1 && 0 && 1 && 0 \\\\\n",
        "  0 && 1 && 0 && 1 \\\\\n",
        "  0 && 0 && 1 && 0 \\\\\n",
        "  0 && 0 && 0 && 1\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "$H$, the observation model matrix, effectively informs the other matrices in the ```kalman()``` function below that we are only measuring $x_{pos}$ and $y_{pos}$\n",
        "\n",
        "$H=\\begin{bmatrix}\n",
        "            1 && 0 && 0 && 0 \\\\\n",
        "            0 && 1 && 0 && 0\n",
        " \\end{bmatrix}$\n",
        "\n",
        "### A note on 'Tuning' the Kalman Filter\n",
        "Setting each term along the diagonal of the $Q$ matrix (the process error covariance term) to 1 works as a 'bucket chemistry' tuning technique for filter responsiveness when working in conjunction with estimates for the $R$ matrix (the observation covariance).  For some projects we have the time and resources to derive statistical models to accurately model $Q$ and $R$ but for some projects - such as this introductory example - its relatively common to tune them quickly by hand.\n",
        "\n",
        "Some tuning tips include:\n",
        "* Trial and error tuning is common;\n",
        "* Setting large values of $Q$ relative to $R$ tells the Kalman Filter to trust the observations more than the model;\n",
        "* setting large values of $R$ relative to $Q$ tells the Kalman Filter to trust the model more than the observations;\n",
        "* setting $Q$ to all ones along the diagonal is reasonably common as its relatively neutral and means you can tune by only adjusting $R$.\n",
        "\n",
        "### A note on types\n",
        "\n",
        "Finally, we initialise everything using floats, to get a self-consistent set of data types - everything is floating point.\n",
        "\n",
        "### Summary\n",
        "\n",
        "With these matrices shaped and initialized, we have specialised a generic ```kalman()``` routine to perform Kalman Filtering using a constant velocity model in two dimensions; x and y.  For simplicity, we are not using $B_{k}$, the control-input model, in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZAHf_dQau78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kalman_2d(x, P, observation, R, Q=np.matrix(np.eye(4))):\n",
        "    x, P = kalman(x, P, observation, R, Q,\n",
        "        # State Transition Model matrix, assuming constant velocity model (x, y, x_dot, y_dot)\n",
        "        F=np.matrix('''\n",
        "            1. 0. 1. 0.;\n",
        "            0. 1. 0. 1.;\n",
        "            0. 0. 1. 0.;\n",
        "            0. 0. 0. 1.\n",
        "            '''),\n",
        "        # Observation Model matrix, assuming we can only measure \n",
        "        # the co-ordinates x, y\n",
        "        H=np.matrix('''\n",
        "            1. 0. 0. 0.;\n",
        "            0. 1. 0. 0.\n",
        "            '''))\n",
        "    return x, P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4RRg22Hitb5",
        "colab_type": "text"
      },
      "source": [
        "#Kalman Filter\n",
        "\n",
        "Derived from Wikipedia\n",
        "\n",
        "    See http://en.wikipedia.org/wiki/Kalman_filter\n",
        "\n",
        "Look back over Kalman Introduction and Kalman Maths for an insight into how Kalman is operating.\n",
        "\n",
        "The concept is:\n",
        "* For a low computational cost\n",
        "* Generate a state update/prediction\n",
        "* Generate a measurement prediction from that state\n",
        "* Calculate the difference between the predicted measurement and the actual measurement\n",
        "* Adjust the state update/prediction, and repeat....\n",
        "\n",
        "All done on normal probabilities - i.e. means and co-variances.  Effectively each key term is held as two parameters - a mean term and a covariance term for that mean.\n",
        "\n",
        "To this filter, we supply the old state / variance and the new measurement value / variance and we take away a new state / variance.\n",
        "\n",
        "Two key terms to watch are the process error estimate covariance term and the observation error estimate covariance term as their interaction influences the filter responsiveness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn7nKwdli4e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kalman(x, P, z, R, Q, F, H):\n",
        "    '''\n",
        "    Dynamic Parameters\n",
        "    x: state estimate\n",
        "    P: state estimate uncertainty covariance\n",
        "    z: observation\n",
        "    R: the covariance of the observation noise\n",
        "\n",
        "    Additionally\n",
        "    F: the state-transition model\n",
        "    H: the observation model - maps true state space into the observed space\n",
        "    Q: the covariance of the process noise\n",
        "\n",
        "    return:\n",
        "        updated and predicted new values for (x, P)\n",
        "    '''\n",
        "    # Update Step\n",
        "    # Update x and P based on measurement m\n",
        "    # distance between measured and current position-belief\n",
        "\n",
        "    # Innovation (or measurement) pre-fit residual\n",
        "    y = np.matrix(z).T - H * x\n",
        "\n",
        "    # Innovation (or pre-fit residual) co-variance\n",
        "    S = H * P * H.T + R\n",
        "\n",
        "    # Optimal Kalman Gain\n",
        "    try:\n",
        "      inv = S.I\n",
        "    except:\n",
        "      inv = np.linalg.pinv(S)\n",
        "    K = P * H.T * inv\n",
        "\n",
        "    # Updated (a posteriori state estimate)\n",
        "    x = x + K * y\n",
        "\n",
        "    # Updated a posteriori estimate co-variance\n",
        "    I = np.matrix(np.eye(F.shape[0]))\n",
        "    P = (I - K*H)*P\n",
        "\n",
        "    # Predict Step\n",
        "    # Predict x and P\n",
        "    x = F*x\n",
        "    P = F*P*F.T + Q\n",
        "\n",
        "    return x, P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dlyv0Nk7EU",
        "colab_type": "text"
      },
      "source": [
        "#Demo\n",
        "\n",
        "## Program Execution\n",
        "For each file:\n",
        "* get centre of detection (if any) and confidence from Yolo\n",
        "* feed Kalman with these values\n",
        "* Extract $x_{pos}$ and $y_{pos}$ from Kalman state term.\n",
        "* Print original centre of detection\n",
        "* Print filtered centre of detection\n",
        "\n",
        "## Initialisation\n",
        "\n",
        "### State Estimate Initialisation\n",
        "We need to initialize the state estimate vector to something.  We'll initialise it to all zeros for reproducibility.\n",
        "\n",
        "\n",
        "$x_{0} = \\begin{bmatrix}\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  0 \\\\\n",
        "  \\end{bmatrix}$\n",
        "\n",
        "### State Estimate Error Covariance Initialisation\n",
        "We need to initialize the state estimate error covariance matrix (estimated accuracy of state estimate).  We'll initialise it along the diagonal as being highly uncertain as shown here.\n",
        "\n",
        "$P_{0} = \\begin{bmatrix}\n",
        " 100 && 0 && 0 && 0 \\\\\n",
        " 0 && 100 && 0 && 0 \\\\\n",
        " 0 && 0 && 100 && 0 \\\\\n",
        " 0 && 0 && 0 && 100\n",
        " \\end{bmatrix}$\n",
        "\n",
        "Typically we initialize the $P$ matrix on the diagonal, with each component corresponding to the expected variance in the corresponding state term, i.e. how much deviation you might expect in the initialization of that state term.  If you have no insight into the behaviour of your model, this is a fairly typical way to get started while figuring out a better $P$ matrix initialisation.\n",
        "\n",
        "### Observation Estimate Noise Covariance\n",
        "And we'll set up a matrix to hold R, the measurement uncertainty (or more formally the estimated covariance of the observation noise.\n",
        "\n",
        " $R_{0} = \\begin{bmatrix}\n",
        "  0 && 0 \\\\\n",
        "  0 && 0 \n",
        "  \\end{bmatrix}$\n",
        "\n",
        "As we process each frame, we're going to adjust this term based on the confidence yolo has in its detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tX2yoKlFiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = None\n",
        "\n",
        "def demo_kalman_2d():\n",
        "    global writer\n",
        "    # Initialise state estimate (x, y, x_dot, y_dot) to no position\n",
        "    x = np.matrix('0. 0. 0. 0.').T\n",
        "    # Initialise uncertainty to all highly uncertain\n",
        "    P = np.matrix(np.eye(4))*100\n",
        "\n",
        "    raw_centres = []        # a list of unfiltered centres\n",
        "    filtered_centres = []   # a list of filtered centres\n",
        "\n",
        "    R = np.zeros(shape=(2, 2))  # a shape to hold measurement uncertainty\n",
        "\n",
        "    bb_lines, pngfiles = get_pngs_and_boxes()\n",
        "\n",
        "    for pngfile in pngfiles:\n",
        "        #print(\"handling ..\" + os.path.basename(pngfile))\n",
        "        img = cv2.imread(pngfile)\n",
        "\n",
        "        # Derive R from yolo confidence level in detection\n",
        "        raw_centre, conf = parse_detections(bb_lines, pngfile, img)\n",
        "\n",
        "        # Crudely derive R (the covariance of the observation noise). \n",
        "        # If yolo is confident we want a small\n",
        "        # uncertainty. If yolo isn't confident, translate to\n",
        "        # a large uncertainty.\n",
        "        R *= 1/conf\n",
        "\n",
        "        # Keep track of unfiltered bounding box centres - these will be\n",
        "        # the basis of our Kalman\n",
        "        raw_centres.append(raw_centre.astype(int))\n",
        "\n",
        "        # reshape observation for Kalman - it expects\n",
        "        # [x]\n",
        "        # [y]\n",
        "        # not [x,y]\n",
        "        observed = raw_centre.reshape(1, 2)\n",
        "\n",
        "        # Update the Kalman with state estimate, state covariance\n",
        "        # observation and observation noise estimate\n",
        "        x, P = kalman_2d(x, P, observed, R)\n",
        "\n",
        "        # just track x and y values from Kalman state\n",
        "        # (we just want to visualise positions)\n",
        "        filtered_centre = x[:2]\n",
        "\n",
        "        # Keep track of filtered x & y values\n",
        "        filtered_centres.append(filtered_centre)\n",
        "\n",
        "        # Pretty print a track of original centres\n",
        "        # and filtered centres\n",
        "        for i in range(1, len(raw_centres)):\n",
        "            # print unfiltered\n",
        "            cv2.line(img, tuple(raw_centres[i-1]), \n",
        "                     tuple(raw_centres[i]), (0, 255, 0), 20)\n",
        "\n",
        "            # print filtered\n",
        "            cv2.line(img, tuple(filtered_centres[i-1]), \n",
        "                     tuple(filtered_centres[i]), (255, 0, 0), 20)\n",
        "\n",
        "        # Resize and show the image\n",
        "        img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
        "\n",
        "        # Build a frame of our output video\n",
        "        if writer is None:\n",
        "            # Initialize our video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'VP80')\n",
        "            writer = cv2.VideoWriter('video.webm', fourcc, 30, (img.shape[1], img.shape[0]), True)\n",
        "\n",
        "        # Write the output frame to disk\n",
        "        writer.write(img)\n",
        "\n",
        "    # Release the file pointers\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "demo_kalman_2d()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fZJvZXeY15y",
        "colab_type": "text"
      },
      "source": [
        "**Video**\n",
        "\n",
        "Thia code plays the video we just made.\n",
        "\n",
        "The Kalman Filtered track plays in green, the unfilterered track plays in blue.\n",
        "\n",
        "As you can see, the Kalman Filtering has a role to play in predicting a reasonable guess for where the object might be while it is off-camera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxvG8It3RlWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set this to 1 if video display\n",
        "# is not working - works with chrome and firefox, not with safari\n",
        "videoBodge = 0\n",
        "\n",
        "def arrayShow (imageArray):\n",
        "    ret, png = cv2.imencode('.png', imageArray)\n",
        "    encoded = base64.b64encode(png)\n",
        "    return Image(data=encoded.decode('ascii'))\n",
        "\n",
        "if(videoBodge == 0):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "    webm = open('video.webm','rb').read()\n",
        "    data_url = \"data:video/webm;base64,\" + b64encode(webm).decode()\n",
        "else:\n",
        "    video = cv2.VideoCapture(\"video.webm\")\n",
        "    while(video.isOpened()):\n",
        "        clear_output(wait=True)\n",
        "        ret, frame = video.read()\n",
        "        if(ret == False):\n",
        "          break\n",
        "        lines, columns, _ =  frame.shape\n",
        "        img = arrayShow(frame)\n",
        "        display(img)\n",
        "        time.sleep(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DewKk12799jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Video\n",
        "HTML(\"\"\"\n",
        "<video width=200 controls>\n",
        "      <source src=\"%s\" type=\"video/webm\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4IGJkZlO_u",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "## Exercises\n",
        "**Exercise 1**\n",
        "Simulate occluding the object being detected - for example, only supply every second measurement update to the Kalman algorithm and observe the Kalman predictions.\n",
        "\n",
        "**Exercise 2**\n",
        "Again, similarly to the Bayes lab, vary the initial state covariance, process covariance and the measurement covariance relative to each other and observe how that affects the Kalman Filter's predictions.\n",
        "\n",
        "**Advanced Exercise**\n",
        "Think about how you might extend the model to account for acceleration in x and y.\n",
        "\n",
        "## Takeaways\n",
        "1. You've seen a Kalman Filter used for single object tracking\n",
        "2. You've seen that a Kalman Filter can help deal with occlusions - i.e. in this example the object being tracked disappeared for a few frames and the Kalman continued to predict motion for it based on its model.\n",
        "3. You've seen that a typical approach to writing a Kalman is to develop the core algorithm independent of the number of terms in the state variable and to specialise it for a particular model.\n",
        "\n",
        "## Next Steps\n",
        "1. We'll see the Kalman's strengths lie with predictable behaviour (typically referred to as a linear model) and we'll look at a derivitive technique (the Particle Filter) that attempts to improve the Kalman in the presence of less predictable behaviour (aka a non-linear model)."
      ]
    }
  ]
}