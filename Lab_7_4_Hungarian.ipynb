{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_7_4_Hungarian.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glA3NV9MRl63",
        "colab_type": "text"
      },
      "source": [
        "# Hungarian Auctioning - Lab 7.4\n",
        "\n",
        "## Recap\n",
        "This is the Lab on using a Hungarian Auctioning in CE6003's Object Tracking. You should complete the tasks in this lab as part of the Tracking Multiple Objects / Hungarian Auctioning section of the lesson.\n",
        "\n",
        "Please remember this lab must be completed before taking the quiz at the end of this lesson.\n",
        "\n",
        "First, if we haven't already done so, we need to clone the various images and resources needed to run these labs into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1qGUkYR6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/mcnamarad1971/CE6003.git\n",
        "!git clone https://github.com/EmdaloTechnologies/CE6003.git\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvp_ecbWSB6V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Program Description\n",
        "\n",
        "This program demonstrates a very simple 'allocation' mechanism based on a Hungarian auction. We're using a tracker derived from a Kalman filter, the filter we developed in the Kalman lab. We're going to use Yolo3 for detections - as usual, and we're going to demonstrate tracking multiple objects (people) using this trio of Hungarian, Kalman, Yolo3.\n",
        "\n",
        "# Purpose\n",
        "The  purpose of this lab is to demonstrate how we might use a Hungarian Algorithm for tracking multiple objects in a video stream, in conjunction with a detector and a set of trackers.\n",
        "\n",
        "# Overall Algorithm\n",
        "Based on detections in a previous image:\n",
        "* run a simple Kalman filter to make a prediction about the position of those objects in a new frame\n",
        "* gather the detections for the new frame\n",
        "* use a Hungarian algorithm and a cost function to allocate the new detections to two pools (reasonably optimally at reasonable computational cost)\n",
        "       1.      New detections that best match the old detection's Kalman loops\n",
        "       2.      Completely new detections that need a new Tracker/Kalman to manage them\n",
        "* Finally the Trackers need to be pruned if they haven't had a new detection sufficiently recently\n",
        "  \n",
        "  \n",
        "For demo purposes, we pretty print the trackers back onto the frames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GSU76keSNr7",
        "colab_type": "text"
      },
      "source": [
        "#The Story So Far\n",
        "\n",
        "To illustrate how to track something in a video stream, we have used the following technique to generate a set of images for you to work on.\n",
        "\n",
        "What we did was we generated a short video - just recording a few people walking around, on an iPhone.\n",
        "\n",
        "Then we used ```ffmpeg``` to decompose about 5 seconds of that video down into still images.\n",
        "\n",
        "```ffmpeg -i $vid_in -vf fps=30 people%03d.png```\n",
        "\n",
        "We saved those frames as ```people%03d.png``` in the git repository in the multiple-detections directory at ```images/lab7/```.  You should be able to access them at ```/content/CE6003/images/lab7/multiple-objects```\n",
        "\n",
        "We've run yolo3 over those frames to generate bounding boxes and saved those bounding boxes into the same directory.\n",
        "\n",
        "The file format is comma-separated values and the values are as shown here:\n",
        "\n",
        " frame index | object-type | centre-x | centre-y | width | height | confidence\n",
        " --- | --- | --- | --- | --- | --- | ---\n",
        " int | -1 | float | float | float | float | float\n",
        "\n",
        "* The object type is always a person - that's all we inferred for.\n",
        "* The centre-x and width are fractions of the image's width\n",
        "* The centre-y and height are fractions of the image's height\n",
        "* The confidence is supplied by Yolo3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWphuuLX6hr",
        "colab_type": "text"
      },
      "source": [
        "*What Happens Now*\n",
        "\n",
        "For each image in the directory, in order,\n",
        "* we'll find the centre of the detection in that image (if any)\n",
        "* we'll build a bounding box for the detection in that image\n",
        "* we'' derive a variance term (crudely) from the Yolo confidence for that image\n",
        "\n",
        "This time we'll supply three lists - a list of the centres of the bounding boxes in the frame, a list of the bounding boxes in the frame, and a list of the Yolo confidence terms.\n",
        "\n",
        "These we'll supply to a Kalman tracker and a Hungarian allocation block.\n",
        "\n",
        "Then, we'll explore how a the Hungarian allocator distributes the detections to Kalman-based trackers to track multiple objects in the image stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtBe23X9liX-",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n",
        "\n",
        "We're using standard imports along with some imports to help display our work on colab.  The only thing to note is we're importing scipy's linear_sum_assignment operator.  This will run the Hungarian auction for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYbUsUr_liye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import re\n",
        "import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import time\n",
        "import base64\n",
        "from IPython.display import clear_output, Image, display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFisGCZZl7E-",
        "colab_type": "text"
      },
      "source": [
        "# Major Tunable Parameters\n",
        "\n",
        "This is where we tune the behaviour of our program.\n",
        "\n",
        "There are a few things to look at here:\n",
        "\n",
        "* ```maxAge``` - this is where we're setting the trade-off between treating a detection as part of an old series or starting a new series.  All we do is simply say - if a tracker hasn't had a match for 4 frames, then get rid of it.  If a detection comes in after that, then its a new Tracker.\n",
        "\n",
        "* ```minHits``` - pretty typical - get tracked on the first hit.\n",
        "\n",
        "* ```ndThreshold``` - a tuning parameter for the Hungarian.  The Hungarian is typically greedy and matches as much as it can.  We're just saying here that empirically there are matches of a quality that are too poor and we're not interested in them.\n",
        "\n",
        "* ```minBlockArea``` - for demo purposes, it was a little clearer if we only tracked larger objects in the scene (approx 200 x 200 pixels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6AyHs1vl7fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMGDIR=\"/content/CE6003/images/lab7/multiple-objects/\"\n",
        "\n",
        "# Find pngs and bounding boxes for pngs\n",
        "pngDir = IMGDIR\n",
        "bbDir = IMGDIR\n",
        "\n",
        "# Initialise an OpenCV video writer object\n",
        "writer = None\n",
        "\n",
        "\n",
        "maxAge = 4 # number of consecutive frames containing an unmatched detection before\n",
        "           # a track is deleted\n",
        "\n",
        "minHits = 1 # number of consecutive matches needed to establish a new track\n",
        "\n",
        "ndThreshold = 0.0003    # if the cost of a 'match' between a detection and a tracker\n",
        "                        # is below this - its not the same object and it needs its own tracker\n",
        "\n",
        "minBoxArea = 40000      # Don't track boxes below this value - too small\n",
        "\n",
        "# a list for tracker ids\n",
        "trackerId = 1   # increment this to give an identity to new objects in the image stream\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiDud8hApWPR",
        "colab_type": "text"
      },
      "source": [
        "# Trackers\n",
        "\n",
        "Now, we set up our key data item - a list of trackers. At the moment its just a list - it'll become a list of ```Tracker``` objects whe we use it - defined by the ```Tracker``` class below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fMm3ufIpWqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main Object - our tracker list\n",
        "trackers = [] # the tracker list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsQyMnFpZBUP",
        "colab_type": "text"
      },
      "source": [
        "# Tracker Class\n",
        "\n",
        "Effectively, we need a something to keep track of trackers and it seems reasonable to associate the Kalman code with the tracker by incorporating the Kalman into a ```Tracker``` class.\n",
        "\n",
        "The Kalman code is effectively unchanged from the ```7_2_Kalman``` lab but refactored into a class.\n",
        "\n",
        "Each ```Tracker``` contains:\n",
        "\n",
        "* ```id```: its Identity\n",
        "* ```box```; its bounding box\n",
        "* ```numHits```: how many frames its been detected in\n",
        "* ```numMisses```: how many frames since it was last detected\n",
        "* and it's Kalman terms.\n",
        "\n",
        "See ```7_2_Kalman``` for a description of the Kalman terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lGqvyGZBjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tracker():        # Class to keep track of trackers\n",
        "    def __init__(self):\n",
        "        # Initialise tracker's history\n",
        "        self.id = 0                             # tracker's id\n",
        "        self.box = np.zeros(shape=(2,2))        # bounding box co-ordinates\n",
        "        self.numHits = 0                        # number of detection matches\n",
        "        self.numMisses = 0                      # number of missed detections\n",
        "\n",
        "        self.xState = np.matrix('0. 0. 0. 0.').T\n",
        "\n",
        "        # Process matrix, assuming constant velocity model (x, y, x_dot, y_dot)\n",
        "        self.F = np.matrix('''\n",
        "                       1. 0. 1. 0.;\n",
        "                       0. 1. 0. 1.;\n",
        "                       0. 0. 1. 0.;\n",
        "                       0. 0. 0. 1.\n",
        "                       ''')\n",
        "\n",
        "        # Measurement matrix, assumig we can only measure the co-ordinates\n",
        "        self.H = np.matrix('''\n",
        "                       1. 0. 0. 0.;\n",
        "                       0. 1. 0. 0.\n",
        "                       ''')\n",
        "\n",
        "        # Initialise to all highly uncertain\n",
        "        self.P = np.matrix(np.eye(4)*100)\n",
        "\n",
        "        # Self motion -  we won't work the motion term in this example\n",
        "        self.motion = np.matrix('0. 0. 0. 0.').T\n",
        "\n",
        "        # Initialise the process covariance\n",
        "        self.Q = np.matrix(np.eye(4))\n",
        "\n",
        "        # Initialise the measurement covariance\n",
        "        self.R = np.zeros(shape=(2,2))\n",
        "\n",
        "    def kalmanFilter(self, box, R):\n",
        "        # build z-term by getting box centres\n",
        "        z = np.zeros(shape=(1,2))\n",
        "        z[0][0] = (box[0][0] + box[1][0])/2\n",
        "        z[0][1] = (box[0][1] + box[1][1])/2\n",
        "\n",
        "        x = self.xState\n",
        "\n",
        "        # Update step\n",
        "        S = self.H*self.P*self.H.T + R\n",
        "        K = self.P*self.H.T*S.I         # Kalman Gain\n",
        "        y = np.matrix(z).T - self.H*x   # residual term\n",
        "        x = x + K*y\n",
        "        I = np.matrix(np.eye(self.F.shape[0]))\n",
        "        self.P = (I - K*self.H)*self.P\n",
        "\n",
        "        # Predict Step\n",
        "        # Predict x and P based on measurement\n",
        "        x = self.F*x + self.motion\n",
        "        self.P = self.F*self.P*self.F.T +self.Q\n",
        "\n",
        "        self.xState = x\n",
        "\n",
        "    def box2xstate(self, box):\n",
        "        # convert np.(2x2), [[x1, y1], [x2, y2]]\n",
        "        # to state vector state_x [x, y, x_dot, y_dot]\n",
        "        # by finding centre of box and using that as x,y\n",
        "        self.xState[0] = (box[0][0] + box[1][0]) / 2 # centre x\n",
        "        self.xState[1] = (box[0][1] + box[1][1]) / 2 # centre y\n",
        "\n",
        "    def xstate2box(self):\n",
        "        # use our  xState to update our box\n",
        "        # by finding our box's centre, extracting\n",
        "        # the new centre from xState and moving\n",
        "        # our box by delta centres\n",
        "        newCentre = np.zeros(shape=(2,1))\n",
        "        newCentre[0] = self.xState[0]\n",
        "        newCentre[1] = self.xState[1]\n",
        "        oldCentre = np.zeros(shape=(2,1))\n",
        "        oldCentre[0] = (self.box[0][0] + self.box[1][0]) / 2 # centre x\n",
        "        oldCentre[1] = (self.box[0][1] + self.box[1][1]) / 2 # centre y\n",
        "\n",
        "        return self.adjustBBox(self.box, oldCentre, newCentre)\n",
        "\n",
        "    def adjustBBox(self, box, origCentre, newCentre):\n",
        "        # Just move any box from oldCentre to newCentre\n",
        "        delta = newCentre - origCentre\n",
        "        adjustedBox = np.zeros(shape=(2,2))\n",
        "        adjustedBox[0][0] = box[0][0] + delta[0]\n",
        "        adjustedBox[0][1] = box[0][1] + delta[1]\n",
        "        adjustedBox[1][0] = box[1][0] + delta[0]\n",
        "        adjustedBox[1][1] = box[1][1] + delta[1]\n",
        "        return adjustedBox\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUYGEjA0qEm-",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSMO5ZjMqyKj",
        "colab_type": "text"
      },
      "source": [
        "# getPngsAndBoxes\n",
        "\n",
        "This is a helper function to get a list of png files in a directory and a file of bounding boxes for those pngs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT7LWwuCqyhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPngsAndBoxes():\n",
        "    global pngDir\n",
        "    global bbDir\n",
        "\n",
        "    pngFolder = os.fsencode(pngDir)\n",
        "    bbFolder = os.fsencode(bbDir)\n",
        "\n",
        "    pngFiles = []\n",
        "    for filename in os.listdir(pngFolder):\n",
        "        if filename.decode().endswith(\".png\"):\n",
        "            pngFiles.append(pngDir + filename.decode())\n",
        "    pngFiles.sort()\n",
        "\n",
        "    for filename in os.listdir(bbFolder):\n",
        "        if filename.decode().endswith(\".boxes\"):\n",
        "            bbFilename = bbDir + filename.decode()\n",
        "\n",
        "    bbfh = open(bbFilename, \"r\")\n",
        "    bbLines = bbfh.readlines()\n",
        "    bbfh.close()\n",
        "\n",
        "    return bbLines, pngFiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDJASmq8ZrwJ",
        "colab_type": "text"
      },
      "source": [
        "**Parse Detections**\n",
        "\n",
        "We'll use this function in the main loop to wrangle the detections into the format we want to supply to our Kalman Filter.\n",
        "\n",
        "Essentially it takes the name of png file, an img object and the list of bounding boxes as inputs.\n",
        "\n",
        "It then finds the correct record (if any) for that image in the bounding boxes list and converts the bounding box parameters into a format which we'll use for the rest of the program (it converts back to absolute pixel values).\n",
        "\n",
        "It returns a centre and a confidence value for the image supplied to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zLCDydJqJtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Helper Function\n",
        "#\n",
        "# Similar to Kalman example\n",
        "#\n",
        "# Takes an image and a set of yolo3 bounding boxes\n",
        "# Finds all the bounding boxes above min box area\n",
        "# in a frame and returns them as a list of centres, a list\n",
        "# of bounding boxes and a list of probabiliy estimates\n",
        "#\n",
        "def parseDetections(bBoxes, pngFile, img):\n",
        "    global minBoxArea\n",
        "\n",
        "    index = int(re.findall(r'\\d+', pngFile)[-1])\n",
        "\n",
        "    imgH, imgW = img.shape[:2]\n",
        "\n",
        "    centreList = []\n",
        "    boxList = []\n",
        "    confList = []\n",
        "\n",
        "    for line in bBoxes:\n",
        "        # ((x_plus_w+x)/2)/image.shape[1] # width\n",
        "        # ((y_plus_h+y)/2)/image.shape[0] # height\n",
        "        # (x_plus_w - x)/image.shape[1]\n",
        "        # (y_plus_h - y)/image.shape[0]\n",
        "        lineArray = np.genfromtxt(io.StringIO(line), delimiter=\",\")\n",
        "        lineIndex = int(lineArray[0])\n",
        "        if lineIndex == index:\n",
        "            centre = np.zeros(shape=(2,1))\n",
        "            box = np.zeros(shape=(2,2))\n",
        "            conf = 0.000001 # hack to avoid div by zero\n",
        "            centre = lineArray[2:4]\n",
        "            halfW = lineArray[4] * imgW / 2\n",
        "            halfH = lineArray[5] * imgH / 2\n",
        "            conf += lineArray[6]\n",
        "            centre[0] *= imgW\n",
        "            centre[1] *= imgH\n",
        "            box[0][0] = centre[0] - halfW   # x1\n",
        "            box[0][1] = centre[1] - halfH   # y1\n",
        "            box[1][0] = centre[0] + halfW   # x2\n",
        "            box[1][1] = centre[1] + halfH   # y2\n",
        "            boxW = halfW * 2\n",
        "            boxH = halfH * 2\n",
        "            boxArea = boxW * boxH\n",
        "            if boxArea > minBoxArea:                # dump small boxes\n",
        "                confList.append(conf)\n",
        "                boxList.append(box)\n",
        "                centreList.append(centre.tolist())\n",
        "\n",
        "    return centreList, boxList, confList\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILmqMXLYqP2o",
        "colab_type": "text"
      },
      "source": [
        "# drawBoxLabel\n",
        "\n",
        "A helper function to draw a bounding box and put a label on it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yq3ap0qQU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Helper Function\n",
        "#\n",
        "# Draw a box with a label.  Default label is 'untracked'\n",
        "#\n",
        "def drawBoxLabel(img, bbox, color=(0,255,255), label=\"Untracked\"):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontSize = 1.2\n",
        "\n",
        "    cv2.rectangle(img, (int(bbox[0][0]), int(bbox[0][1])), (int(bbox[1][0]), int(bbox[1][1])), color, 8)\n",
        "    cv2.putText(img, label, (int(bbox[0][0])-25,int(bbox[0][1])-25), font, fontSize, color, 8, cv2.LINE_AA)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLtMG5IisKN8",
        "colab_type": "text"
      },
      "source": [
        "# Hungarian Cost Term\n",
        "\n",
        "This is very important term.\n",
        "\n",
        "The Hungarian is effectively a cost minimisation function but we need to provide it with a way of expressing *the likelihood that two bounding boxes represent the same object* as a single number.\n",
        "\n",
        "The way we're using the Hungarian function is it actually tries to find the max cost, so we want a term that is more **expensive** if the two boxes are likely to represent the same object and **cheaper** if the two boxes are not likely to represent the same image.\n",
        "\n",
        "So, we need something that generates a larger cost if the boxes are likely to be the same object and a smaller cost if the boxes are unlikely to be the same object\n",
        "\n",
        "The Hungarian will then find the set of relationships with the overall highest cost.\n",
        "\n",
        "We simply used Euclidian distance - boxes that are closer together are more likely to be the same box. So, the smaller the distance between the centres of the boxes the more likely they are to represent the same object.\n",
        "\n",
        "However, that's an inverse relationship to what our Hungarian needs so we simply invert it.  Our best boxes have a difference of 0 between Kalman prediction and new detection so after inverting we can end up with a divide by zero so we just set it to 1 - the best possible match under our this scheme\n",
        "\n",
        "This function could be a candidate for something like a linear regression:\n",
        " * to understand contributions to a cost functon from things like\n",
        " * Bounding Box Size\n",
        " * Bounding Box Overlap\n",
        " * Distance Bounding Boxes are from each other\n",
        " * How long since we last saw an image\n",
        " * How similar the images represented by the two boxes are. etc...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asa2kt_IwbF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def boxCost(box1, box2):\n",
        "    # width and height of box1\n",
        "    # get centre of box1\n",
        "    w1 = box1[1][0] - box1[0][0]\n",
        "    w1 = w1/2\n",
        "    cx1 = box1[0][0] + w1\n",
        "    h1 = box1[1][1] - box1[0][1]\n",
        "    h1 = h1/2\n",
        "    cy1 = box1[0][1] + h1\n",
        "\n",
        "    # width and height of box2\n",
        "    # get centre of box2\n",
        "    w2 = box2[1][0] - box2[0][0]\n",
        "    w2 = w2/2\n",
        "    cx2 = box2[0][0] + w2\n",
        "    h2 = box2[1][1] - box2[0][1]\n",
        "    h2 = h2/2\n",
        "    cy2 = box2[0][1] + h2\n",
        "\n",
        "    xDist = abs(cx2 - cx1)\n",
        "    yDist = abs(cy2 - cy1)\n",
        "\n",
        "    # square root of x squared plus y squared\n",
        "    cost = xDist**2 + yDist**2\n",
        "    cost = math.sqrt(cost)\n",
        "\n",
        "    # Invert to get what we need for\n",
        "    # this implementation of Hungarian\n",
        "    if cost == 0:\n",
        "        cost = 1\n",
        "    else:\n",
        "        cost = 1/cost   # bigger cost if closer\n",
        "\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orFcPPX7wgB9",
        "colab_type": "text"
      },
      "source": [
        "# assignDetectionsToTrackers\n",
        "\n",
        "This operates by building a cost matrix of the current trackers and the new detections and using a Hungarian auction to re-order them for best cost.\n",
        "\n",
        "It returns three lists:\n",
        " * matches (matched)\n",
        " * trackers without detections (unmatchedTrackers)\n",
        " * detections without trackers (unmatchedDetections)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGhzoplWxRsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def assignDetectionsToTrackers(trackers, detections):\n",
        "    global ndThreshold      # tweak the output of the Hungarian - it can produce poor matches\n",
        "\n",
        "    # Build a cost matrix - all zeros (size determined by num trackers and detections\n",
        "    # Set it up as float to match our cost function\n",
        "    costMatrix = np.zeros((len(trackers), len(detections)), dtype=np.float32)\n",
        "\n",
        "    # Fill the cost matrix with 'prices' derived from the\n",
        "    # cost term\n",
        "    # A cost for every combination of tracker and new detection\n",
        "    for t,trk in enumerate(trackers):\n",
        "        for d,det in enumerate(detections):\n",
        "            costMatrix[t,d] = boxCost(trk,det)\n",
        "\n",
        "    # Produce matches\n",
        "    # Solve the maximising of the sum of cost asignment using the\n",
        "    # Hungarian algorithm (aka Munkres algorithm)\n",
        "    matchedRowIdx, matchedColIdx = linear_sum_assignment(-costMatrix)\n",
        "\n",
        "    # First of all find any tracker that didn't find a date\n",
        "    # with a new detection at all\n",
        "    # add it to the unmatchedTrackers list\n",
        "    # Maybe that object has gone away ...\n",
        "    unmatchedTrackers, unmatchedDetections = [], []\n",
        "    for t,trk in enumerate(trackers):\n",
        "        if(t not in matchedRowIdx):\n",
        "            unmatchedTrackers.append(t)\n",
        "\n",
        "    # Now find any detection that didn't find a date\n",
        "    # with an old trackeer  at all\n",
        "    # add it to the unmatchedDetections list\n",
        "    # Maybe its a new object\n",
        "    for d, det in enumerate(detections):\n",
        "        if(d not in matchedColIdx):\n",
        "            unmatchedDetections.append(d)\n",
        "\n",
        "    # Now, look at the matches in more detail\n",
        "    # Maybe there's a few matches that are not\n",
        "    # going to work\n",
        "    matches = []\n",
        "\n",
        "    # If the cost is than nd_theshold then\n",
        "    # override the match - its not good enough\n",
        "    # If you change the cost function, you'll probably\n",
        "    # need to change ndThreshold as well\n",
        "    for m, _ in enumerate(matchedRowIdx):\n",
        "        if(costMatrix[matchedRowIdx[m],matchedColIdx[m]]<ndThreshold):\n",
        "            # Nope, not really a match\n",
        "            # add the detection to unmatched detections list\n",
        "            # add the tracker to unmatched tracker list\n",
        "            unmatchedTrackers.append(matchedRowIdx[m])\n",
        "            unmatchedDetections.append(matchedColIdx[m])\n",
        "        else:\n",
        "            # Its a match\n",
        "            # Record details of the match - tracker index and detection index\n",
        "            match = np.empty((1,2),dtype=int)\n",
        "            match[0][0] = matchedRowIdx[m]\n",
        "            match[0][1] = matchedColIdx[m]\n",
        "            # Add to matches list\n",
        "            matches.append(match)\n",
        "\n",
        "    # Clean and return\n",
        "    if(len(matches)==0):\n",
        "        matches = np.empty((0,2),dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches,axis=0)\n",
        "\n",
        "    return matches, np.array(unmatchedDetections), np.array(unmatchedTrackers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY1UrdsExTKT",
        "colab_type": "text"
      },
      "source": [
        "# demoHungarian\n",
        "\n",
        "Here is the main code\n",
        "\n",
        "For each png in a directory:\n",
        " * open it\n",
        " * get the bounding boxes for it\n",
        " * attempt to match the bounding boxes with any existing trackers\n",
        " * get three lists:\n",
        "   * matches\n",
        "   * untracked detections\n",
        "   * trackers with no detections\n",
        " * Handle all three cases\n",
        "   * Update and display matches\n",
        "   * Age (and prune) unmatched trackers\n",
        "   * Create new trackers for unmatched detections\n",
        "   \n",
        "Finally pretty print matched detections and trackers to video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tX2yoKlFiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def demoHungarian():\n",
        "    global trackerId\n",
        "    global writer\n",
        "    global trackers\n",
        "\n",
        "    # Initialise state to no position\n",
        "    x = np.matrix('0. 0. 0. 0.').T\n",
        "    # Initialise state uncertainty covariance\n",
        "    P = np.matrix(np.eye(4))*100\n",
        "\n",
        "    # Create an empty box\n",
        "    box = np.zeros(shape=(2,2))\n",
        "\n",
        "    # Get lists of files and bounding boxes\n",
        "    bbLines, pngFiles = getPngsAndBoxes()\n",
        "\n",
        "    # Main loop - do this for every image in the directory\n",
        "    for pngFile in pngFiles:\n",
        "        #print (\"handling ..\" + os.path.basename(pngFile))\n",
        "        # Load the file\n",
        "        img = cv2.imread(pngFile)\n",
        "\n",
        "        # Gather a list of new boxes and confidence values\n",
        "        # We'll use this confidence in R term of Kalman\n",
        "        # Derive R from yolo confidence level in detection\n",
        "        _, newBoxes, newConfs = parseDetections(bbLines, pngFile, img)\n",
        "\n",
        "        # Build our known boxes list by extracting it from our list\n",
        "        # of tracker objects - each tracker has a box its minding for us\n",
        "        knownBoxes = []\n",
        "\n",
        "        if(len(trackers) > 0):\n",
        "            for trk in trackers:\n",
        "                knownBoxes.append(trk.box)\n",
        "\n",
        "        # Now we have a list of old boxes being tracked and a\n",
        "        # list of new boxes.\n",
        "        # Hand over to assignment function to build our\n",
        "        # three lists - matched, unmatched detections and unmatched trackers\n",
        "        matched, unmatchedDetections, unmatchedTrackers \\\n",
        "        = assignDetectionsToTrackers(knownBoxes, newBoxes)\n",
        "\n",
        "        # Deal with matched detections\n",
        "        if(matched.size > 0):\n",
        "            for trkIdx, detIdx in matched:\n",
        "                # there was a match\n",
        "                # new data for tracked object\n",
        "                box = newBoxes[detIdx]\n",
        "                conf = newConfs[detIdx]\n",
        "                R = np.eye(2)\n",
        "                R *= 1/conf\n",
        "                # find tracker in list\n",
        "                tmpTrk = trackers[trkIdx]\n",
        "                # update its data and run a kalman filter\n",
        "                tmpTrk.kalmanFilter(box, R)\n",
        "                tmpTrk.box = box\n",
        "                knownBoxes[trkIdx] = tmpTrk.box\n",
        "                tmpTrk.numHits += 1\n",
        "                tmpTrk.numMisses = 0\n",
        "\n",
        "        # Deal with unmatched detections\n",
        "        if (len(unmatchedDetections)>0):\n",
        "            for idx in unmatchedDetections:\n",
        "                box  = newBoxes[idx]\n",
        "                tmpTrk = Tracker() # create a new tracker\n",
        "                tmpTrk.box = box\n",
        "                tmpTrk.box = tmpTrk.xstate2box()\n",
        "                tmpTrk.id = trackerId # assign ID to tracker\n",
        "                trackerId += 1\n",
        "                trackers.append(tmpTrk)\n",
        "                knownBoxes.append(tmpTrk.box)\n",
        "\n",
        "        # Deal with unmatched tracks\n",
        "        if (len(unmatchedTrackers)>0):\n",
        "            for trkIdx in unmatchedTrackers:\n",
        "                tmpTrk = trackers[trkIdx]\n",
        "                tmpTrk.numMisses += 1\n",
        "                tmpTrk.box = tmpTrk.xstate2box()\n",
        "                knownBoxes[trkIdx] = tmpTrk.box\n",
        "\n",
        "        # The list of tracks to be displayed\n",
        "        for trk in trackers:\n",
        "            if ((trk.numHits >= minHits) and (trk.numMisses <= maxAge)):\n",
        "                drawBoxLabel(img, trk.box, label=\"Tracked \" + str(trk.id))\n",
        "\n",
        "        # clean up deleted tracks\n",
        "        trackers = [x for x in trackers if x.numMisses <= maxAge]\n",
        "\n",
        "        # Resize and show the image\n",
        "        vidout = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
        "\n",
        "        # Build a frame of our output video\n",
        "        if writer is None:\n",
        "            # Initialize our video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'VP80')\n",
        "            writer = cv2.VideoWriter('video.webm', fourcc, 30, (vidout.shape[1], vidout.shape[0]), True)\n",
        "\n",
        "        # Write the output frame to disk\n",
        "        writer.write(vidout)\n",
        "\n",
        "    # Release the file pointers\n",
        "    writer.release()\n",
        "\n",
        "demoHungarian()\n",
        "\n",
        "!ls video.webm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fZJvZXeY15y",
        "colab_type": "text"
      },
      "source": [
        "**Video**\n",
        "\n",
        "Thia code plays the video we just made.\n",
        "\n",
        "The Tracked objects are boxed and labelled i yellow with an tracker number for each object.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxvG8It3RlWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set this to 1 if video display\n",
        "# is not working - works with chrome and firefox, not with safari\n",
        "videoBodge = 0\n",
        "\n",
        "def arrayShow (imageArray):\n",
        "    ret, png = cv2.imencode('.png', imageArray)\n",
        "    encoded = base64.b64encode(png)\n",
        "    return Image(data=encoded.decode('ascii'))\n",
        "\n",
        "if(videoBodge == 0):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "    webm = open('video.webm','rb').read()\n",
        "    data_url = \"data:video/webm;base64,\" + b64encode(webm).decode()\n",
        "else:\n",
        "    video = cv2.VideoCapture(\"video.webm\")\n",
        "    while(video.isOpened()):\n",
        "        clear_output(wait=True)\n",
        "        ret, frame = video.read()\n",
        "        if(ret == False):\n",
        "          break\n",
        "        lines, columns, _ =  frame.shape\n",
        "        img = arrayShow(frame)\n",
        "        display(img)\n",
        "        time.sleep(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2A8A2r48OcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Video\n",
        "HTML(\"\"\"\n",
        "<video width=200 controls>\n",
        "      <source src=\"%s\" type=\"video/webm\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4IGJkZlO_u",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "## Exercises\n",
        "**Exercise 1**\n",
        "Reduce the ```minBoxArea``` to effectively track smaller boxes - you may also need to assign a ```colour``` term to the tracker as I'd expect there to be more objects to track and it should become harder to see what the program is doing.  What does happen?\n",
        "\n",
        "**Exercise 2**\n",
        "Rework ```boxCost``` to combine:\n",
        " 1. Euclidean Distance\n",
        " 2. One other term that you think might improve the cost function, e.g.:\n",
        "  * similarity of bounding box size;\n",
        "  * bounding box percentage overlap\n",
        "  * etc...\n",
        "\n",
        "Don't forget the ```ndThreshold``` term will need to be adjusted as well.  Does it improve the tracking.\n",
        "\n",
        "**Optional Exercise 2**\n",
        "Rework ```boxCost``` to use Mahalanobis distance instead of Euclidean distance. See https://en.wikipedia.org/wiki/Mahalanobis_distance for details.\n",
        "\n",
        "## Takeaways\n",
        "1. You've seen three items working in concert; a detector, a tracker and an allocator to track multiple objects in video.\n",
        "\n",
        "2. You've seen that how you define your cost function in the allocation scheme is critical.\n",
        "\n",
        "3. You've adjusted a simple cost function yourself.\n",
        "\n",
        "4. You have the concept that you can use smarter trackers, smarter, detectors and a smarter allocation cost function if you have the computational budget for it.\n",
        "\n",
        "## Next Steps\n",
        "1. We'll look at a completely different type of tracker now - based on Optical Flow\n",
        "\n",
        "2. Finally, we'll review contemporary approaches to tracking using CNNs."
      ]
    }
  ]
}