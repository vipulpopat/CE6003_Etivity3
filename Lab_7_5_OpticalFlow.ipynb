{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_7_5_OpticalFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glA3NV9MRl63",
        "colab_type": "text"
      },
      "source": [
        "# Optical Flow - Lab 7.5\n",
        "\n",
        "## Recap\n",
        "This is the Lab on using an Optical Flow based algorithm to track a person as CE6003's Object Tracking section. You should complete the tasks in this lab as part of the Optical Flow section of the lesson.\n",
        "\n",
        "Please remember this lab must be completed before taking the quiz at the end of this lesson.\n",
        "\n",
        "First, if we haven't already done so, we need to clone the various images and resources needed to run these labs into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md1qGUkYR6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/EmdaloTechnologies/CE6003.git\n",
        "#!git clone https://github.com/mcnamarad1971/CE6003.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvp_ecbWSB6V",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Program Description**\n",
        "\n",
        "This program demonstrates a very simple 'tracking' mechanism - derived from a Optical Flow algorithm. We're going to use OpenCV's Lucas Kanade algorithm to track a single object, namely a person.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8wilg5Xfiqi",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n",
        "\n",
        "Standard imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWvUXFH1iaoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import clear_output, Image, display\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GSU76keSNr7",
        "colab_type": "text"
      },
      "source": [
        "#The Story So Far\n",
        "\n",
        "To illustrate how to track something in a video stream, we have done a little work offline.  We have located a bounding box enclosing the object of interest in the first frame of the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWphuuLX6hr",
        "colab_type": "text"
      },
      "source": [
        "*What Happens Now*\n",
        "\n",
        "For the first frame in the video, we'll use our pre-rolled points to define a region of interest.  We know - a priori - where the object we want to track is in the first frame.\n",
        "\n",
        "We'll find some good features to track in that image (corners mainly) and then pass that set of corners to Lucas-Kanade algorithm along with the old frame and the new frame.  It will return a set of corners in the new frame that is its best estimate of where the ROI has moved to.\n",
        "\n",
        "We''ll find the centre of those points and use that as a tracker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY4bHjZsuWQ2",
        "colab_type": "text"
      },
      "source": [
        "**Key Parameters**\n",
        "\n",
        "We have two key parameters to shape our optical flow tracker.  We have a set of parameters for the Lucas-Kanade optical flow estimation and we have a rejection radius.  Any points outside the radius are disregarded for tracking purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JujHzAd7iWo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for Lucas Kanade optical flow\n",
        "lkParams = dict( winSize = (15,15),\n",
        "                  maxLevel = 2,\n",
        "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Rejection radius - points outside a circle with this radius are deemed to be not part of the object we're tracking\n",
        "rejRadius = 200\n",
        "\n",
        "# The bounding box we are interested in in the first frame\n",
        "defX1 = 500\n",
        "defX2 = 700\n",
        "defY1 = 1000\n",
        "defY2 = 1800\n",
        "\n",
        "# A video writer\n",
        "writer = None\n",
        "\n",
        "# A frame grabber\n",
        "fg = cv2.VideoCapture(\"/content/CE6003/images/lab7/vids/daire.mp4\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMx7acIMbnfY",
        "colab_type": "text"
      },
      "source": [
        "We need a helper function to find Euclidean distance.  We use this to locate points inside and outside the radius of interest.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO1sRVeRbb4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Euclidean Distance term\n",
        "def findDistance(x1, y1, x2, y2):\n",
        "        d = (x1-x2)**2 + (y1-y2)**2\n",
        "        d = np.sqrt(d)\n",
        "        return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4RRg22Hitb5",
        "colab_type": "text"
      },
      "source": [
        "#Optical Flow\n",
        "\n",
        "Look back over Optical Flow Concept video for an insight into how it is operating.\n",
        "\n",
        "The concept is:\n",
        "* For a low computational cost\n",
        "* Generate a set of features - usually corners.\n",
        "* Give those corners to the Lucas-Kanade algorithm.  It will find the region in the next frame that best matches those corners and supplies that region\n",
        "* Calculate the difference between the predicted measurement of the selected particles and the actual measurement\n",
        "* Adjust the state update/prediction particles (through a resampling stage to prevent degeneration of filter), and repeat....\n",
        "\n",
        "Done on Monte Carlo sampled particles.\n",
        "\n",
        "One key term to watch is how many particles to use for your specific tracking application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dlyv0Nk7EU",
        "colab_type": "text"
      },
      "source": [
        "##Demo\n",
        "\n",
        "### Program Execution\n",
        "For each frame:\n",
        "* get centre of detection (if any) and confidence from Yolo\n",
        "* feed Particle Filter with these values\n",
        "* Print internal Particles used by Particle Filter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tX2yoKlFiS",
        "colab_type": "code",
        "outputId": "4962da00-640a-4663-ea96-76a419b80ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def demo_of():\n",
        "    global writer\n",
        "    global fg\n",
        "    global lkParams\n",
        "    global rejRadius\n",
        "    global defX1\n",
        "    global defX2\n",
        "    global defY1\n",
        "    global defY2\n",
        "\n",
        "    vidScale = 4\n",
        "\n",
        "    # Read one frame initially\n",
        "    ret, frame = fg.read()\n",
        "\n",
        "    # Convert it to grayScale\n",
        "    newFrameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # calculate a region of interest - roi\n",
        "    x1 = defX1\n",
        "    x2 = defX2\n",
        "    y1 = defY1\n",
        "    y2 = defY2\n",
        "    roi = newFrameGray[y1:y2, x1:x2]\n",
        "\n",
        "    # get some corners\n",
        "    newCorners = cv2.goodFeaturesToTrack(roi, 50, 0.01, 10)\n",
        "\n",
        "    # translate corners from roi frame to image frame\n",
        "    newCorners[:,0,0] = newCorners[:,0,0] + x1\n",
        "    newCorners[:,0,1] = newCorners[:,0,1] + y1\n",
        "\n",
        "    # Draw the corners we're tracking in the original image\n",
        "    for corner in newCorners:\n",
        "        cv2.circle(frame, (int(corner[0][0]), int(corner[0][1])), 5, (0,255,0))\n",
        "\n",
        "    vidout = cv2.resize(frame, (int(frame.shape[1]/vidScale), int(frame.shape[0]/vidScale)))\n",
        "    #cv2_imshow(vidout)\n",
        "\n",
        "    if writer is None:\n",
        "        # Initialize our video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'VP80')\n",
        "        writer = cv2.VideoWriter('video.webm', fourcc, 30, \n",
        "                                 (vidout.shape[1], vidout.shape[0]), True)\n",
        "\n",
        "    # Write the output frame to disk\n",
        "    writer.write(vidout)\n",
        "\n",
        "    # set up old corners and old frame\n",
        "    oldFrameGray = newFrameGray.copy()\n",
        "    oldCorners = newCorners.copy()\n",
        "\n",
        "    # start tracking\n",
        "    while True:\n",
        "        # New we have an old frame, we can get\n",
        "        # a new_frame, we have old_corners and\n",
        "        # we can get new_corners, and update accordingly\n",
        "\n",
        "        # read new frame and convert to gray\n",
        "        ret, frame = fg.read()\n",
        "        if ret == False:\n",
        "            break\n",
        "\n",
        "        # Grayscale\n",
        "        newFrameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # find the new tracked points\n",
        "        newCorners, st, err = cv2.calcOpticalFlowPyrLK(oldFrameGray, \n",
        "                                                       newFrameGray, \n",
        "                                                       oldCorners, \n",
        "                                                       None, **lkParams)\n",
        "\n",
        "        # Prune far away points\n",
        "        mean = newCorners.mean(axis=0)\n",
        "        mean = mean.astype(int)\n",
        "\n",
        "        # draw the centroid\n",
        "        cv2.circle(frame, (mean[0][0],mean[0][1]),int(rejRadius),(255,0,0), 20)\n",
        "\n",
        "        # keep only those corners \n",
        "        # which are at a distance of rejRadius or less\n",
        "        # use a list expression\n",
        "        newCorners = np.array([i for i in newCorners if \n",
        "                               findDistance(i[0][0], i[0][1], mean[0][0], \n",
        "                                            mean[0][1]) <= rejRadius])\n",
        "\n",
        "        # draw the new points\n",
        "        for corner in newCorners:\n",
        "            cv2.circle(frame, (int(corner[0][0]),int(corner[0][1])),5,(0,255,0))\n",
        "\n",
        "        if len(newCorners) < 10:\n",
        "            print ('Lost Object', len(newCorners))\n",
        "            break\n",
        "\n",
        "        # Find minimum enclosing circle\n",
        "        ctr, rad = cv2.minEnclosingCircle(newCorners)\n",
        "\n",
        "        # Draw this circle\n",
        "        cv2.circle(frame, (int(ctr[0]),int(ctr[1])),int(rad),(0,0,255),thickness=5)\n",
        "\n",
        "        # Update old_corners and oldFrameGray\n",
        "        oldFrameGray = newFrameGray.copy()\n",
        "        oldCorners = newCorners.copy()\n",
        "\n",
        "        vidout = cv2.resize(frame, (int(frame.shape[1]/vidScale), int(frame.shape[0]/vidScale)))\n",
        "\n",
        "        # Write the output frame to disk\n",
        "        writer.write(vidout)\n",
        "\n",
        "    # Release the file pointers\n",
        "    writer.release()\n",
        "\n",
        "demo_of()\n",
        "\n",
        "!ls video.webm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "video.webm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fZJvZXeY15y",
        "colab_type": "text"
      },
      "source": [
        "**Video**\n",
        "\n",
        "Thia code plays the video we just made.\n",
        "\n",
        "The individual corners identified by the Shi-Tomasi / Lucas-Kanade are in green.\n",
        "\n",
        "The 'object' is in red and the rejection limit is in blue.\n",
        "\n",
        "As you can see, Optical Flow has a role to play in object tracking but it can struggle with occlusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxvG8It3RlWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set this to 1 if video display\n",
        "# is not working - works with chrome and firefox, not with safari\n",
        "videoBodge = 0\n",
        "\n",
        "def arrayShow (imageArray):\n",
        "    ret, png = cv2.imencode('.png', imageArray)\n",
        "    encoded = base64.b64encode(png)\n",
        "    return Image(data=encoded.decode('ascii'))\n",
        "\n",
        "if(videoBodge == 0):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "    webm = open('video.webm','rb').read()\n",
        "    data_url = \"data:video/webm;base64,\" + b64encode(webm).decode()\n",
        "else:\n",
        "    video = cv2.VideoCapture(\"video.webm\")\n",
        "    while(video.isOpened()):\n",
        "        clear_output(wait=True)\n",
        "        ret, frame = video.read()\n",
        "        if(ret == False):\n",
        "          break\n",
        "        lines, columns, _ =  frame.shape\n",
        "        img = arrayShow(frame)\n",
        "        display(img)\n",
        "        time.sleep(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YnbLXhhoO1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Video\n",
        "HTML(\"\"\"\n",
        "<video width=200 controls>\n",
        "      <source src=\"%s\" type=\"video/webm\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4IGJkZlO_u",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "## Exercises\n",
        "**Exercise 1**\n",
        "Answer the question - would taking a new set corners on each iteration improve the algorithm's performance?\n",
        "\n",
        "**Stretch 1**\n",
        "Convert the program to track using a dense optical flow algorithm.\n",
        "\n",
        "\n",
        "## Takeaways\n",
        "1. You've seen a Sparse Optical Flow used for single object tracking\n",
        "2. You've seen that it did't deal terribly well with occlusions - i.e. in this example the object being tracked disappeared for a few frames and the Optical Flow based tracker lost it at that point.\n",
        "3. You've seen that you probably need to tune the Filter to get it working for a particular application.\n",
        "\n",
        "## Next Steps\n",
        "1. We'll look at one last tracking approach based on a CNN Feature based tracker."
      ]
    }
  ]
}